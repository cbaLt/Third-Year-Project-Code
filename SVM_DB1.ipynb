{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Formatting Functions"
      ],
      "metadata": {
        "id": "Vx5eMQsMPOW-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "altvJi4oOjiF"
      },
      "outputs": [],
      "source": [
        "import scipy.io as sio\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "from skimage.feature import hog\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import SVC\n",
        "import os\n",
        "import scipy.sparse as sp\n",
        "import scipy.io as sio\n",
        "import time\n",
        "import cuml\n",
        "from cuml.svm import SVC as cuSVC\n",
        "import cudf\n",
        "import scipy.stats\n",
        "import librosa\n",
        "import cupy as cp\n",
        "import h5py\n",
        "import gc\n",
        "from scipy.stats import mode\n",
        "import string\n",
        "\n",
        "def rolling_window(arr, window_len, step):\n",
        "\n",
        "    num_windows = (len(arr) - window_len) // step + 1\n",
        "    windows = np.zeros((num_windows, window_len), dtype=arr.dtype)\n",
        "\n",
        "    for i in range(num_windows):\n",
        "        start = i * step\n",
        "        end = start + window_len\n",
        "        windows[i] = arr[start:end]\n",
        "\n",
        "    return windows\n",
        "\n",
        "def rolling_window_electrodes(arr, window_len, step):\n",
        "\n",
        "    num_windows = (arr.shape[1] - window_len) // step + 1\n",
        "    windows = np.zeros((arr.shape[0], num_windows, window_len), dtype=arr.dtype)\n",
        "\n",
        "    for i in range(num_windows):\n",
        "      start = i * step\n",
        "      end = start + window_len\n",
        "      windows[:, i] = arr[:, start:end]  # Slice along columns\n",
        "\n",
        "    return windows\n",
        "\n",
        "def one_hot_encoder(labels, gestures):\n",
        "\n",
        "        one_hot = np.zeros((len(labels), gestures))\n",
        "\n",
        "        for index, value in enumerate(labels):\n",
        "            label_encode = int(value)\n",
        "            one_hot[index][label_encode] = 1\n",
        "\n",
        "        return one_hot\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To run"
      ],
      "metadata": {
        "id": "zOXW4wY5PahA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from google.colab import drive\n",
        "\n",
        "# ONLY DB1 evaulated here\n",
        "database = 'DB1'\n",
        "\n",
        "# CHANGE AS APPRORIATE\n",
        "evaluation = 'STFT'\n",
        "\n",
        "# ok, so E2 and E3 adjusted means to adjust them gesture back to 1-N gestures, otherwise it is say 18-40 but depending on what gesture set went first\n",
        "data_dict = {\n",
        "        'DB1': {'E1': 13, 'E2': 18, 'E3': 24, 'E1_adjusted': 0, 'E2_adjusted': 0, 'E3_adjusted': 0, 'fs': 100, 'electrodes': 10, 'subjects': 27, 'train': [1, 3, 4, 6, 7, 8, 9], 'test': [2, 5, 10], 'window length': 20, 'step': 1},\n",
        "        'DB2': {'E1': 18, 'E2': 24, 'E3': 10, 'E1_adjusted': 0, 'E2_adjusted': -17, 'E3_adjusted': -40, 'fs': 100, 'electrodes': 12, 'subjects': 40, 'train': [1, 3, 4, 6], 'test': [2, 5], 'window length': 20, 'step': 1},\n",
        "        'DB3': {'E1': 18, 'E2': 24, 'E3': 10, 'E1_adjusted': 0, 'E2_adjusted': -17, 'E3_adjusted': -40, 'fs': 200, 'electrodes': 12, 'subjects': 11, 'train': [1, 3, 4, 6], 'test': [2, 5], 'window length': 40, 'step': 2},\n",
        "        'DB4': {'E1': 13, 'E2': 18, 'E3': 24, 'E1_adjusted': 0, 'E2_adjusted': 0, 'E3_adjusted': 0,'fs': 200, 'electrodes': 12, 'subjects': 10, 'train': [1, 3, 4, 6], 'test': [2, 5], 'window length': 40, 'step': 2},\n",
        "        'DB5': {'E1': 13, 'E2': 18, 'E3': 24, 'E1_adjusted': 0, 'E2_adjusted': 0, 'E3_adjusted': 0,'fs': 200, 'electrodes': 16, 'subjects': 10, 'train': [1, 3, 4, 6], 'test': [2, 5], 'window length': 40, 'step': 2}\n",
        "        }\n",
        "\n",
        "num_subjects = data_dict[database]['subjects']\n",
        "fs = data_dict[database]['fs']\n",
        "num_electrodes = data_dict[database]['electrodes']\n",
        "\n",
        "train_trials =  data_dict[database]['train']\n",
        "test_trials = data_dict[database]['test']\n",
        "M, step = data_dict[database]['window length'], data_dict[database]['step']\n",
        "num_freq_bins = int((fs / 2) / (1 / (1/fs * M)))\n",
        "freq_bins = np.linspace(0, fs/2, num_freq_bins)\n",
        "\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_c95JcS6Pdun",
        "outputId": "3cd21c86-1023-413f-bad6-6a5d93c0a3b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# javasript to simulate button click\n",
        "%%javascript\n",
        "function ClickConnect(){\n",
        "    console.log(\"Clicked on connect button\");\n",
        "    document.querySelector(\"colab-connect-button\").click()\n",
        "}\n",
        "setInterval(ClickConnect,60000)"
      ],
      "metadata": {
        "id": "k7zHy0AKR1IK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "17cad84d-18fc-40e6-bda2-60cb36d9d5f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "function ClickConnect(){\n",
              "    console.log(\"Clicked on connect button\");\n",
              "    document.querySelector(\"colab-connect-button\").click()\n",
              "}\n",
              "setInterval(ClickConnect,60000)\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "M8gO5S8NPmGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "from sklearn.metrics import accuracy_score\n",
        "import seaborn as sns\n",
        "import scipy.sparse as sp\n",
        "\n",
        "tot_num_gestures = data_dict[database]['E1'] + data_dict[database]['E2'] + data_dict[database]['E3'] - 2\n",
        "combined_cm = np.zeros((tot_num_gestures, tot_num_gestures), dtype=int)\n",
        "accuracy_dict = {'E1': [], 'E2': [], 'E3': []}\n",
        "\n",
        "for exercise in ['E1', 'E2', 'E3']:\n",
        "\n",
        "  label_dict = {f'S{num}': [] for num in range(1, num_subjects+1)}\n",
        "  features_dict = {f'S{num}': [] for num in range(1, num_subjects+1)}\n",
        "  num_gestures = data_dict[database][exercise]\n",
        "\n",
        "  # for all subjects\n",
        "  for subject in range(1,(num_subjects+1)):\n",
        "      gc.collect()\n",
        "\n",
        "      # load EMG data\n",
        "      file = sio.loadmat(f'/content/drive/My Drive/uni/{database}/Electrode Data/S{subject}_A1_{exercise}.mat')\n",
        "      label = file['restimulus'].flatten()\n",
        "      trials = np.int8(file['rerepetition']).flatten()\n",
        "\n",
        "\n",
        "      windowed_trials = rolling_window(trials, M, step)\n",
        "      trials_arr = [np.max(arr) for arr in windowed_trials]\n",
        "\n",
        "      train_feature_path = f'/content/drive/My Drive/uni/{database}/Features_down/DATA2_{exercise}_S{subject}_features.h5'\n",
        "      with h5py.File(train_feature_path, 'r') as feature_file:\n",
        "\n",
        "          mav = feature_file['MAV'][:]\n",
        "          mavs = feature_file['MAVS'][:]\n",
        "          wap = feature_file['WAP'][:]\n",
        "          zcr = feature_file['ZC'][:]\n",
        "          ar1 = feature_file['ar1'][:]\n",
        "          ar2 = feature_file['ar2'][:]\n",
        "          ar3 = feature_file['ar3'][:]\n",
        "          ar4 = feature_file['ar4'][:]\n",
        "          wl = feature_file['WL'][:]\n",
        "          ssc = feature_file['SSC'][:]\n",
        "          var = feature_file['VAR'][:]\n",
        "          iemg = feature_file['IEMG'][:]\n",
        "          rms = feature_file['RMS'][:]\n",
        "\n",
        "      if evaluation == 'HHT':\n",
        "          hht_train_path = f'/content/drive/My Drive/uni/{database}/HHT/{exercise}_S{subject}_hht.h5'\n",
        "      elif evaluation == 'STFT':\n",
        "          hht_train_path = f'/content/drive/My Drive/uni/{database}/STFT/{exercise}_S{subject}_stft.h5'\n",
        "\n",
        "      with h5py.File(hht_train_path, 'r') as hht_file:\n",
        "          mean_freq = hht_file['mean freq'][:]\n",
        "          skew_freq = hht_file['skew freq'][:]\n",
        "          psr = hht_file['psr'][:]\n",
        "          #train_imfs = hht_file['num imfs'][:]\n",
        "          peak_freq = hht_file['peak freq'][:]\n",
        "          mean_power = hht_file['mean power'][:]\n",
        "          kurt_freq = hht_file['kurt freq'][:]\n",
        "          var_freq = hht_file['var freq'][:]\n",
        "\n",
        "      if evaluation == 'HHT':\n",
        "          mean_power = np.squeeze(mean_power)\n",
        "          mean_freq = np.squeeze(mean_freq)\n",
        "          psr = np.squeeze(psr)\n",
        "          mean_power = np.squeeze(mean_power)\n",
        "          mean_freq = np.squeeze(mean_freq)\n",
        "          psr = np.squeeze(psr)\n",
        "\n",
        "      # feature set 1\n",
        "      #features = np.concatenate([mean_freq.T, psr.T, wl.T], axis=1)\n",
        "\n",
        "      # feature set 2\n",
        "      #features = np.concatenate([mean_power.T, wl.T], axis=1)\n",
        "\n",
        "      # feature set 3\n",
        "      #features = np.concatenate([mean_power.T, wl.T, mav.T], axis=1)\n",
        "\n",
        "      # feature set 4\n",
        "      #features = np.concatenate([iemg.T, var.T, wap.T, wl.T, ssc.T, zcr.T, mean_power.T], axis=1)\n",
        "\n",
        "      # feature set 5\n",
        "      #features = np.concatenate([iemg.T, var.T, wap.T, wl.T, ssc.T, zcr.T], axis=1)\n",
        "\n",
        "      # feature set 6\n",
        "      #features = np.concatenate([mav.T, wl.T, ssc.T, zcr.T], axis=1)\n",
        "\n",
        "      # feature set 7\n",
        "      #features = np.concatenate([mav.T, wl.T, ssc.T, zcr.T, mean_power.T], axis=1)\n",
        "\n",
        "      # feature set 8\n",
        "      features = np.concatenate([mav.T, mavs.T,  wap.T, zcr.T, ar1.T, ar2.T, ar3.T, ar4.T, wl.T, mean_freq.T, psr.T], axis=1)\n",
        "\n",
        "      # window labels\n",
        "      label_arr = rolling_window(label, M, step)\n",
        "      label_arr = np.array([np.max(arr) for arr in label_arr])\n",
        "\n",
        "      # split training / test trials\n",
        "      train_index = []\n",
        "      test_index = []\n",
        "      for index, val in enumerate(trials):\n",
        "        if val in train_trials:\n",
        "          train_index.append(index)\n",
        "        elif val in test_trials:\n",
        "          test_index.append(index)\n",
        "\n",
        "      train_features = features[train_index, :]\n",
        "      train_label_one = label_arr[train_index]\n",
        "\n",
        "      test_features = features[test_index, :]\n",
        "      test_label_one = label_arr[test_index]\n",
        "\n",
        "      print(train_features.shape, test_features.shape)\n",
        "\n",
        "      # adjust gestures back to 1-N - it's a list\n",
        "      print(\"fitting model now\")\n",
        "\n",
        "      # SVM\n",
        "      X_cudf = cudf.DataFrame(train_features, dtype=np.float32)\n",
        "      y_cudf = cudf.Series(train_label_one, dtype=np.float32)\n",
        "\n",
        "      clf = cuSVC(kernel='rbf', C=5.0)\n",
        "      clf.fit(X_cudf, y_cudf)\n",
        "      x_test = cudf.DataFrame(test_features, dtype=np.float32)\n",
        "      y_test = cudf.Series(test_label_one, dtype=np.float32)\n",
        "\n",
        "      # SVM predicition\n",
        "      label_prediction = clf.predict(x_test)\n",
        "      accuracy = accuracy_score(y_test.to_numpy(), label_prediction.to_numpy())\n",
        "      print(f\"{exercise}, S{subject} Accuracy: {(accuracy*100):.2f}\")\n",
        "\n",
        "      accuracy_dict[exercise].append(accuracy*100)\n",
        "      del clf\n",
        "\n",
        "for key in accuracy_dict.keys():\n",
        "  print(f'Average accuracy for {key}: {np.mean(accuracy_dict[key])}, and std: {np.std(accuracy_dict[key], ddof=1)}')\n",
        "  print(f'num elements {len(accuracy_dict[key])}')\n",
        "\n",
        "ye = []\n",
        "for val in accuracy_dict.values():\n",
        "  ye.extend(val)\n",
        "# print overall accuracy and sample standard deviation\n",
        "print(f'Overall average: {np.mean(ye)} and std: {np.std(ye, ddof=1)}')\n"
      ],
      "metadata": {
        "id": "_lgIMLgBPoSD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}