{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "collapsed_sections": [
        "Vx5eMQsMPOW-"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Formatting Functions"
      ],
      "metadata": {
        "id": "Vx5eMQsMPOW-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "altvJi4oOjiF"
      },
      "outputs": [],
      "source": [
        "import scipy.io as sio\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "from skimage.feature import hog\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import SVC\n",
        "import os\n",
        "import scipy.sparse as sp\n",
        "import scipy.io as sio\n",
        "import time\n",
        "import cuml\n",
        "from cuml.svm import SVC as cuSVC\n",
        "import cudf\n",
        "import scipy.stats\n",
        "import librosa\n",
        "import cupy as cp\n",
        "import h5py\n",
        "import gc\n",
        "from scipy.stats import mode\n",
        "import string\n",
        "\n",
        "# to split data like papers for reproducibility\n",
        "def split_trials(trial_data, num_gestures, training_trials, test_trials):\n",
        "\n",
        "    # calculate number of trials from arrays given. Create 3D array to store indices for each trial, for each gesture\n",
        "    num_trials = len(training_trials) + len(test_trials)\n",
        "    trial_index = np.zeros((num_trials, num_gestures, 2))\n",
        "\n",
        "    curr_label = 0                                     # label indexed from 0, so gesture 1 is label 0 etc.\n",
        "    for i in range(1, len(trial_data)):\n",
        "        curr_trial = trial_data[i]- 1              # minus 1 to make zero indexed - trial 1 is 0 etc.\n",
        "        prev_trial = trial_data[i-1] - 1\n",
        "\n",
        "        if curr_trial != prev_trial:                   # store index at beginning and end of trial\n",
        "\n",
        "            # zero indexed\n",
        "            if curr_trial == 0:                                 # if trial is zero (trial 1), that means it is a new gesture (label)\n",
        "                trial_index[prev_trial][curr_label][1] = i      # store index for beginning of that trial, for that gesture\n",
        "                curr_label += 1                                 # update gesture (label) by 1\n",
        "\n",
        "                trial_index[curr_trial][curr_label][0] = i      # store index for end of that trial - it is an index for range() function, so this value will not be included, e.g. 2017, means up to 2016\n",
        "\n",
        "            else:\n",
        "                trial_index[prev_trial][curr_label][1] = i      # same as before, except there is no need to update gesture (label), as trial is between 1-6 (or 0-5 zero-indexed)\n",
        "                trial_index[curr_trial][curr_label][0] = i\n",
        "\n",
        "    # update last trial, last gesture (label) beginning index, as it is wrong!!\n",
        "    trial_index[(num_trials-1)][(num_gestures-1)][0] = trial_index[(num_trials-2)][(num_gestures-1)][1]\n",
        "\n",
        "    return trial_index\n",
        "\n",
        "def split_labels(index_info, label_data, training_trials, test_trials):\n",
        "\n",
        "    training_labels, test_labels = [], []\n",
        "\n",
        "    # use the indices found to create arrays for training data (labels and features)\n",
        "    for j in training_trials:\n",
        "        trial_num = j-1\n",
        "\n",
        "        for indices in index_info[trial_num]:\n",
        "                beg, end = int(indices[0]), int(indices[1])\n",
        "\n",
        "                # slice the training labels and features\n",
        "                training_labels = np.append(training_labels, label_data[beg:end])\n",
        "\n",
        "    # use the indices found to slice testing features and labels\n",
        "    for j in test_trials:\n",
        "        trial_num = j-1\n",
        "\n",
        "        for indices in index_info[trial_num]:\n",
        "\n",
        "                beg, end = int(indices[0]), int(indices[1])\n",
        "                test_labels = np.append(test_labels, label_data[beg:end])\n",
        "\n",
        "    return training_labels, test_labels\n",
        "\n",
        "def rolling_window(arr, window_len, step, arr_dimension):\n",
        "\n",
        "    if arr_dimension == 2:\n",
        "        num_windows = (arr.shape[0] - window_len) // step + 1\n",
        "        windows = np.zeros((num_windows, window_len, arr.shape[1]), dtype=arr.dtype)\n",
        "    elif arr_dimension == 1:\n",
        "        num_windows = (len(arr) - window_len) // step + 1\n",
        "        windows = np.zeros((num_windows, window_len), dtype=arr.dtype)\n",
        "\n",
        "    for i in range(num_windows):\n",
        "        start = i * step\n",
        "        end = start + window_len\n",
        "        windows[i] = arr[start:end]\n",
        "\n",
        "    return windows\n",
        "\n",
        "def rolling_window_electrodes(arr, window_len, step):\n",
        "\n",
        "    num_windows = (arr.shape[1] - window_len) // step + 1\n",
        "    windows = np.zeros((arr.shape[0], num_windows, window_len), dtype=arr.dtype)\n",
        "\n",
        "    for i in range(num_windows):\n",
        "      start = i * step\n",
        "      end = start + window_len\n",
        "      windows[:, i] = arr[:, start:end]  # Slice along columns\n",
        "\n",
        "    return windows\n",
        "\n",
        "def one_hot_encoder(labels, gestures):\n",
        "\n",
        "        one_hot = np.zeros((len(labels), gestures))\n",
        "\n",
        "        for index, value in enumerate(labels):\n",
        "            label_encode = int(value)\n",
        "            one_hot[index][label_encode] = 1\n",
        "\n",
        "        return one_hot\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To run"
      ],
      "metadata": {
        "id": "zOXW4wY5PahA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from google.colab import drive\n",
        "\n",
        "# CHANGE AS APPROPRIATE\n",
        "database = 'DB3'\n",
        "#CHANGE AS APPROPRIATE\n",
        "evaluation = 'STFT'\n",
        "\n",
        "# ok, so E2 and E3 adjusted means to adjust them gesture back to 1-N gestures, otherwise it is say 18-40 but depending on what gesture set went first\n",
        "data_dict = {\n",
        "        'DB1': {'E1': 13, 'E2': 18, 'E3': 24, 'E1_adjusted': 0, 'E2_adjusted': 0, 'E3_adjusted': 0, 'fs': 100, 'electrodes': 10, 'subjects': 27, 'train': [1, 3, 4, 6, 7, 8, 9], 'test': [2, 5, 10], 'window length': 20, 'step': 1},\n",
        "        'DB2': {'E1': 18, 'E2': 24, 'E3': 10, 'E1_adjusted': 0, 'E2_adjusted': -17, 'E3_adjusted': -40, 'fs': 100, 'electrodes': 12, 'subjects': 40, 'train': [1, 3, 4, 6], 'test': [2, 5], 'window length': 20, 'step': 1},\n",
        "        'DB3': {'E1': 18, 'E2': 24, 'E3': 10, 'E1_adjusted': 0, 'E2_adjusted': -17, 'E3_adjusted': -40, 'fs': 200, 'electrodes': 12, 'subjects': 11, 'train': [1, 3, 4, 6], 'test': [2, 5], 'window length': 40, 'step': 2},\n",
        "        'DB4': {'E1': 13, 'E2': 18, 'E3': 24, 'E1_adjusted': 0, 'E2_adjusted': 0, 'E3_adjusted': 0,'fs': 200, 'electrodes': 12, 'subjects': 10, 'train': [1, 3, 4, 6], 'test': [2, 5], 'window length': 40, 'step': 2},\n",
        "        'DB5': {'E1': 13, 'E2': 18, 'E3': 24, 'E1_adjusted': 0, 'E2_adjusted': 0, 'E3_adjusted': 0,'fs': 200, 'electrodes': 16, 'subjects': 10, 'train': [1, 3, 4, 6], 'test': [2, 5], 'window length': 40, 'step': 2}\n",
        "        }\n",
        "\n",
        "num_subjects = data_dict[database]['subjects']\n",
        "fs = data_dict[database]['fs']\n",
        "num_electrodes = data_dict[database]['electrodes']\n",
        "\n",
        "train_trials =  data_dict[database]['train']\n",
        "test_trials = data_dict[database]['test']\n",
        "M, step = data_dict[database]['window length'], data_dict[database]['step']\n",
        "num_freq_bins = int((fs / 2) / (1 / (1/fs * M)))\n",
        "freq_bins = np.linspace(0, fs/2, num_freq_bins)\n",
        "\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_c95JcS6Pdun",
        "outputId": "28cf13a7-45be-474e-8c70-36c6229ef2f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# javascript to prevent idle timeout\n",
        "%%javascript\n",
        "function ClickConnect(){\n",
        "    console.log(\"Clicked on connect button\");\n",
        "    document.querySelector(\"colab-connect-button\").click()\n",
        "}\n",
        "setInterval(ClickConnect,60000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "k7zHy0AKR1IK",
        "outputId": "ccb63b0c-a18d-4d4b-d82a-ff0a39642972"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "function ClickConnect(){\n",
              "    console.log(\"Clicked on connect button\");\n",
              "    document.querySelector(\"colab-connect-button\").click()\n",
              "}\n",
              "setInterval(ClickConnect,60000)\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "M8gO5S8NPmGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "from sklearn.metrics import accuracy_score\n",
        "import scipy.sparse as sp\n",
        "\n",
        "tot_num_gestures = data_dict[database]['E1'] + data_dict[database]['E2'] + data_dict[database]['E3'] - 2\n",
        "combined_cm = np.zeros((tot_num_gestures, tot_num_gestures), dtype=int)\n",
        "accuracy_dict = {'E1': [], 'E2': [], 'E3': []}\n",
        "\n",
        "for exercise in ['E1', 'E2', 'E3']:\n",
        "\n",
        "  label_dict = {f'S{num}': [] for num in range(1, num_subjects+1)}\n",
        "  features_dict = {f'S{num}': [] for num in range(1, num_subjects+1)}\n",
        "  num_gestures = data_dict[database][exercise]\n",
        "\n",
        "  # for all subjects\n",
        "  for subject in range(1,(num_subjects+1)):\n",
        "      # to prevent issues with SVM\n",
        "      gc.collect()\n",
        "\n",
        "      # subjects 6 and 7 were not evaulated for DB3\n",
        "      if database == 'DB3':\n",
        "        if subject in [6,7]:\n",
        "          continue\n",
        "\n",
        "      file = sio.loadmat(f'/content/drive/My Drive/{database}/Electrode Data/S{subject}_{exercise}_A1.mat')\n",
        "      label = file['restimulus'].flatten()\n",
        "      trials = np.int8(file['rerepetition']).flatten()\n",
        "\n",
        "      if database in ['DB3', 'DB4']:\n",
        "        downsample_factor = 10\n",
        "        label = label[::downsample_factor]\n",
        "        trials = trials[::downsample_factor]\n",
        "\n",
        "      # find indexes of where trials begin and end\n",
        "      trial_split_index = split_trials(trials, num_gestures, train_trials, test_trials)\n",
        "      # split labels with trial info\n",
        "      train_labels, test_labels = split_labels(trial_split_index, label, train_trials, test_trials)\n",
        "\n",
        "      train_feature_path = f'/content/drive/My Drive/{database}/Features_down/Training_{exercise}_S{subject}_features.h5'\n",
        "      with h5py.File(train_feature_path, 'r') as train_file:\n",
        "          train_mav = train_file['MAV'][:]\n",
        "          train_mavs = train_file['MAVS'][:]\n",
        "          train_wap = train_file['WAP'][:]\n",
        "          train_zcr = train_file['ZC'][:]\n",
        "          train_ssc = train_file['SSC'][:]\n",
        "          train_ar1 = train_file['ar1'][:]\n",
        "          train_ar2 = train_file['ar2'][:]\n",
        "          train_ar3 = train_file['ar3'][:]\n",
        "          train_ar4 = train_file['ar4'][:]\n",
        "          train_wl = train_file['WL'][:]\n",
        "          train_rms = train_file['RMS'][:]\n",
        "          train_ssc = train_file['SSC'][:]\n",
        "          train_var = train_file['VAR'][:]\n",
        "          train_iemg = train_file['IEMG'][:]\n",
        "\n",
        "      test_feature_path = f'/content/drive/My Drive/{database}/Features_down/Test_{exercise}_S{subject}_features.h5'\n",
        "      with h5py.File(test_feature_path, 'r') as test_file:\n",
        "          test_mav = test_file['MAV'][:]\n",
        "          test_mavs = test_file['MAVS'][:]\n",
        "          test_wap = test_file['WAP'][:]\n",
        "          test_zcr = test_file['ZC'][:]\n",
        "          test_ssc = test_file['SSC'][:]\n",
        "          test_ar1 = test_file['ar1'][:]\n",
        "          test_ar2 = test_file['ar2'][:]\n",
        "          test_ar3 = test_file['ar3'][:]\n",
        "          test_ar4 = test_file['ar4'][:]\n",
        "          test_wl = test_file['WL'][:]\n",
        "          test_rms = test_file['RMS'][:]\n",
        "          test_ssc = test_file['SSC'][:]\n",
        "          test_var = test_file['VAR'][:]\n",
        "          test_iemg = test_file['IEMG'][:]\n",
        "\n",
        "      if evaluation == 'HHT':\n",
        "          hht_train_path = f'/content/drive/My Drive/{database}/HHT/Training_{exercise}_S{subject}_hht.h5'\n",
        "      elif evaluation == 'STFT':\n",
        "          hht_train_path = f'/content/drive/My Drive/{database}/STFT/Training_{exercise}_S{subject}_stft.h5'\n",
        "\n",
        "      with h5py.File(hht_train_path, 'r') as hht_file:\n",
        "          train_mean_freq = hht_file['mean freq'][:]\n",
        "          train_skew_freq = hht_file['skew freq'][:]\n",
        "          train_psr = hht_file['psr'][:]\n",
        "          #train_imfs = hht_file['num imfs'][:]\n",
        "          train_peak_freq = hht_file['peak freq'][:]\n",
        "          train_mean_power = hht_file['mean power'][:]\n",
        "          train_kurt_freq = hht_file['kurt freq'][:]\n",
        "          train_var_freq = hht_file['var freq'][:]\n",
        "\n",
        "      if evaluation == 'HHT':\n",
        "          hht_test_path = f'/content/drive/My Drive/{database}/HHT/Test_{exercise}_S{subject}_hht.h5'\n",
        "      elif evaluation == 'STFT':\n",
        "          hht_test_path = f'/content/drive/My Drive/{database}/STFT/Test_{exercise}_S{subject}_stft.h5'\n",
        "\n",
        "      with h5py.File(hht_test_path, 'r') as hht_file:\n",
        "          test_mean_freq = hht_file['mean freq'][:]\n",
        "          test_skew_freq = hht_file['skew freq'][:]\n",
        "          test_psr = hht_file['psr'][:]\n",
        "          #test_imfs = hht_file['num imfs'][:]\n",
        "          test_peak_freq = hht_file['peak freq'][:]\n",
        "          test_mean_power = hht_file['mean power'][:]\n",
        "          test_kurt_freq = hht_file['kurt freq'][:]\n",
        "          test_var_freq = hht_file['var freq'][:]\n",
        "\n",
        "      if evaluation == 'HHT':\n",
        "          train_mean_power = np.squeeze(train_mean_power)\n",
        "          train_mean_freq = np.squeeze(train_mean_freq)\n",
        "          train_psr = np.squeeze(train_psr)\n",
        "          test_mean_power = np.squeeze(test_mean_power)\n",
        "          test_mean_freq = np.squeeze(test_mean_freq)\n",
        "          test_psr = np.squeeze(test_psr)\n",
        "\n",
        "      # set 1\n",
        "      #train_features = np.concatenate([train_mean_freq.T, train_psr.T, train_wl.T], axis=1)\n",
        "      #test_features = np.concatenate([test_mean_freq.T, test_psr.T, test_wl.T], axis=1)\n",
        "\n",
        "      # set 2\n",
        "      #train_features = np.concatenate([train_mean_power.T, train_wl.T], axis=1)\n",
        "      #test_features = np.concatenate([test_mean_power.T, test_wl.T], axis=1)\n",
        "\n",
        "      # set 3\n",
        "      #train_features = np.concatenate([train_mean_power.T, train_wl.T, train_mav.T], axis=1)\n",
        "      #test_features = np.concatenate([test_mean_power.T, test_wl.T, test_mav.T], axis=1)\n",
        "\n",
        "      # set 4\n",
        "      #train_features = np.concatenate([train_iemg.T, train_var.T, train_wap.T, train_wl.T, train_ssc.T, train_zcr.T, train_mean_power.T], axis=1)\n",
        "      #test_features = np.concatenate([test_iemg.T, test_var.T, test_wap.T, test_wl.T, test_ssc.T, test_zcr.T, test_mean_power.T], axis=1)\n",
        "\n",
        "      # set 5\n",
        "      #train_features = np.concatenate([train_iemg.T, train_var.T, train_wap.T, train_wl.T, train_ssc.T, train_zcr.T], axis=1)\n",
        "      #test_features = np.concatenate([test_iemg.T, test_var.T, test_wap.T, test_wl.T, test_ssc.T, test_zcr.T], axis=1)\n",
        "\n",
        "      # set 6\n",
        "      #train_features = np.concatenate([train_mav.T, train_wl.T, train_ssc.T, train_zcr.T], axis=1)\n",
        "      #test_features = np.concatenate([test_mav.T, test_wl.T, test_ssc.T, test_zcr.T], axis=1)\n",
        "\n",
        "      # set 7\n",
        "      #train_features = np.concatenate([train_mav.T, train_wl.T, train_ssc.T, train_zcr.T, train_mean_power.T], axis=1)\n",
        "      #test_features = np.concatenate([test_mav.T, test_wl.T, test_ssc.T, test_zcr.T, test_mean_power.T], axis=1)\n",
        "\n",
        "      # set 8\n",
        "      train_features = np.concatenate([train_mav.T, train_mavs.T, train_wap.T, train_zcr.T, train_ar1.T, train_ar2.T, train_ar3.T, train_ar4.T, train_wl.T, train_mean_freq.T, train_psr.T], axis=1)\n",
        "      test_features = np.concatenate([test_mav.T, test_mavs.T, test_wap.T, test_zcr.T, test_ar1.T, test_ar2.T, test_ar3.T, test_ar4.T, test_wl.T, test_mean_freq.T, test_psr.T], axis=1)\n",
        "\n",
        "      print(train_features.shape, test_features.shape)\n",
        "\n",
        "      # window labels - only to predict whether gesture or not\n",
        "      test_label_arr = rolling_window(test_labels, M, step, 1)\n",
        "      train_label_arr = rolling_window(train_labels, M, step, 1)\n",
        "\n",
        "      # format labels\n",
        "      train_label_one = [np.max(arr) for arr in train_label_arr]\n",
        "      test_label_one = [np.max(arr) for arr in test_label_arr]\n",
        "\n",
        "      print(np.unique(test_label_one))\n",
        "\n",
        "      # adjust gestures back to 1-N - it's a list\n",
        "      train_label_ = [x + data_dict[database][f'{exercise}_adjusted'] if x != 0 else 0 for x in train_label_one]\n",
        "      test_label_ = [x + data_dict[database][f'{exercise}_adjusted'] if x != 0 else 0 for x in test_label_one]\n",
        "      print(\"fitting model now\")\n",
        "\n",
        "      # SVM\n",
        "      X_cudf = cudf.DataFrame(train_features, dtype=np.float32)\n",
        "      y_cudf = cudf.Series(train_label_, dtype=np.float32)\n",
        "\n",
        "      # fit SVM\n",
        "      clf = cuSVC(kernel='rbf', C=5.0)\n",
        "      clf.fit(X_cudf, y_cudf)\n",
        "      x_test = cudf.DataFrame(test_features, dtype=np.float32)\n",
        "      y_test = cudf.Series(test_label_, dtype=np.float32)\n",
        "\n",
        "      label_prediction = clf.predict(x_test)\n",
        "      accuracy = accuracy_score(y_test.to_numpy(), label_prediction.to_numpy())\n",
        "      print(f\"{exercise}, S{subject} Accuracy: {(accuracy*100):.2f}\")\n",
        "\n",
        "      accuracy_dict[exercise].append(accuracy*100)\n",
        "      del clf\n",
        "\n",
        "for key in accuracy_dict.keys():\n",
        "  print(f'Average accuracy for {key}: {np.mean(accuracy_dict[key])}, and std: {np.std(accuracy_dict[key], ddof=1)}')\n",
        "  print(f'num elements {len(accuracy_dict[key])}')\n",
        "\n",
        "ye = []\n",
        "for val in accuracy_dict.values():\n",
        "  ye.extend(val)\n",
        "# display average and sample standard deviation\n",
        "print(f'Overall average: {np.mean(ye)} and std: {np.std(ye, ddof=1)}')\n"
      ],
      "metadata": {
        "id": "_lgIMLgBPoSD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}